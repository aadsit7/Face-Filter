<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Snapchat-Style Face Filter</title>

  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- TensorFlow + WASM backend for iPhone -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@3.21.0/dist/tf-backend-wasm.min.js"></script>

  <!-- face-api.js -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
    }
    .tab-active {
      background-color: rgb(37 99 235);
      color: white;
    }
    .tab-inactive {
      background-color: transparent;
      color: rgb(55 65 81);
    }
  </style>
</head>
<body class="bg-gray-50 min-h-screen flex flex-col">

  <div class="container mx-auto px-6 py-6 flex-1">

    <header class="mb-6">
      <h1 class="text-3xl font-semibold">Snapchat-Style Face Filter</h1>
      <p class="text-gray-600 mt-1">Upload any image → apply as a live face filter.</p>
    </header>

    <!-- Tabs -->
    <nav class="flex mb-6 bg-white rounded-full p-1 shadow-md">
      <button id="tab-upload-btn" class="flex-1 py-2 tab-active rounded-full" data-tab="upload">Upload Image</button>
      <button id="tab-camera-btn" class="flex-1 py-2 tab-inactive rounded-full" data-tab="camera">Camera Filter</button>
    </nav>

    <main>

      <!-- Upload Tab -->
      <section id="upload-tab" class="bg-white rounded-2xl shadow-md p-6">
        <h2 class="text-xl mb-4">Upload Filter Image</h2>

        <label for="upload-input" class="inline-block bg-blue-600 text-white px-6 py-2 rounded-full cursor-pointer">
          Choose Image
        </label>

        <input id="upload-input" type="file" class="hidden" accept="image/png, image/jpeg">

        <div id="upload-preview-wrapper" class="hidden mt-4">
          <p class="text-gray-600 mb-2">Preview:</p>
          <img id="upload-preview" class="max-w-full rounded-lg border" />
        </div>

        <p id="upload-message" class="text-green-700 mt-4 hidden">
          Image uploaded! Switch to the Camera Filter tab.
        </p>
      </section>

      <!-- Camera Tab -->
      <section id="camera-tab" class="hidden bg-white rounded-2xl shadow-md p-6 mt-6">
        <h2 class="text-xl mb-4">Camera Filter</h2>

        <p id="no-image-message" class="text-gray-700">Please upload an image first.</p>

        <button id="start-camera" class="hidden bg-blue-600 text-white px-6 py-2 rounded-full mt-4">
          Start Camera
        </button>

        <div id="camera-container" class="relative mt-6 hidden">
          <video id="video" autoplay muted playsinline class="hidden"></video>
          <canvas id="canvas" class="rounded-lg border"></canvas>
        </div>

        <p id="status-message" class="text-xs text-gray-500 mt-4">Loading models…</p>
      </section>

    </main>

  </div>

  <script>
    let uploadedImage = null;
    let upperMaskCanvas = null;
    let lowerMaskCanvas = null;

    let video = null;
    let canvas = null;
    let ctx = null;

    let modelsLoaded = false;
    let isCameraRunning = false;

    let blinkFrames = 0;
    let baselineMouthOpen = null;

    const MODEL_URL = "https://aadsit7.github.io/Face-Filter/models";

    const tabUploadBtn = document.getElementById("tab-upload-btn");
    const tabCameraBtn = document.getElementById("tab-camera-btn");
    const uploadTab = document.getElementById("upload-tab");
    const cameraTab = document.getElementById("camera-tab");

    function showTab(tab) {
      if (tab === "upload") {
        uploadTab.classList.remove("hidden");
        cameraTab.classList.add("hidden");
        tabUploadBtn.classList.add("tab-active");
        tabCameraBtn.classList.remove("tab-active");
        stopCamera();
      } else {
        uploadTab.classList.add("hidden");
        cameraTab.classList.remove("hidden");
        tabCameraBtn.classList.add("tab-active");
      }
    }

    tabUploadBtn.addEventListener("click", () => showTab("upload"));
    tabCameraBtn.addEventListener("click", () => showTab("camera"));

    async function loadModels() {
      document.getElementById("status-message").textContent = "Loading models…";

      await tf.setBackend("wasm");
      await tf.ready();

      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);

      modelsLoaded = true;
      document.getElementById("status-message").textContent =
        "Models loaded. Upload an image.";
    }

    loadModels();

    const uploadInput = document.getElementById("upload-input");
    uploadInput.addEventListener("change", (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const reader = new FileReader();
      reader.onload = (event) => {
        const img = new Image();
        img.onload = () => {
          uploadedImage = img;

          document.getElementById("upload-preview").src = img.src;
          document.getElementById("upload-preview-wrapper").classList.remove("hidden");
          document.getElementById("upload-message").classList.remove("hidden");

          splitMask(img);
          updateCameraUI();
        };

        img.src = event.target.result;
      };

      reader.readAsDataURL(file);
    });

    function splitMask(img) {
      const splitRatio = 0.55;
      const splitY = img.height * splitRatio;

      upperMaskCanvas = document.createElement("canvas");
      upperMaskCanvas.width = img.width;
      upperMaskCanvas.height = splitY;
      upperMaskCanvas.getContext("2d").drawImage(img, 0, 0, img.width, splitY, 0, 0, img.width, splitY);

      lowerMaskCanvas = document.createElement("canvas");
      lowerMaskCanvas.width = img.width;
      lowerMaskCanvas.height = img.height - splitY;
      lowerMaskCanvas.getContext("2d").drawImage(
        img,
        0,
        splitY,
        img.width,
        img.height - splitY,
        0,
        0,
        img.width,
        img.height - splitY
      );
    }

    function updateCameraUI() {
      const startBtn = document.getElementById("start-camera");
      const msg = document.getElementById("no-image-message");

      if (uploadedImage && modelsLoaded) {
        msg.textContent = "Click Start Camera";
        startBtn.classList.remove("hidden");
      }
    }

    document.getElementById("start-camera").addEventListener("click", startCamera);

    async function startCamera() {
      video = document.getElementById("video");
      canvas = document.getElementById("canvas");
      ctx = canvas.getContext("2d");

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" }
      });

      video.srcObject = stream;

      video.onloadedmetadata = () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        isCameraRunning = true;

        document.getElementById("camera-container").classList.remove("hidden");
        document.getElementById("video").classList.remove("hidden");

        renderLoop();
      };
    }

    function stopCamera() {
      if (video && video.srcObject) {
        video.srcObject.getTracks().forEach((t) => t.stop());
      }
      isCameraRunning = false;
    }

    function avg(ptArr) {
      return ptArr.reduce((a, p) => ({ x: a.x + p.x / ptArr.length, y: a.y + p.y / ptArr.length }), { x: 0, y: 0 });
    }

    function dist(a, b) {
      return Math.hypot(a.x - b.x, a.y - b.y);
    }

    function ear(eye) {
      const v1 = dist(eye[1], eye[5]);
      const v2 = dist(eye[2], eye[4]);
      const h = dist(eye[0], eye[3]);
      return (v1 + v2) / (2 * h);
    }

    async function renderLoop() {
      if (!isCameraRunning) return;

      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const det = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 320 }))
        .withFaceLandmarks();

      if (det) drawFilter(det);

      requestAnimationFrame(renderLoop);
    }

    function drawFilter(det) {
      const lms = det.landmarks;

      const leftEye = avg(lms.getLeftEye());
      const rightEye = avg(lms.getRightEye());
      const nose = avg(lms.getNose());

      const cx = (leftEye.x + rightEye.x) / 2;
      const cy = (leftEye.y * 2 + nose.y) / 3;

      const dx = rightEye.x - leftEye.x;
      const dy = rightEye.y - leftEye.y;
      const angle = Math.atan2(dy, dx);

      const box = det.detection.box;
      const faceWidth = box.width;

      const overlayWidth = faceWidth * 2.2;
      const maskAspect = uploadedImage.height / uploadedImage.width;
      const overlayHeight = overlayWidth * maskAspect;

      const upperH = overlayHeight * (upperMaskCanvas.height / uploadedImage.height);
      const lowerH = overlayHeight * (lowerMaskCanvas.height / uploadedImage.height);

      const topY = cy - overlayHeight * 0.5;

      // Mouth
      const mouth = lms.getMouth();
      const open =
        Math.abs(mouth[13].y - mouth[19].y) +
        Math.abs(mouth[14].y - mouth[18].y) +
        Math.abs(mouth[15].y - mouth[17].y);

      if (baselineMouthOpen == null) baselineMouthOpen = open;

      const jaw = Math.max(0, open - baselineMouthOpen * 1.1) * 1.2;

      // Blink
      const eLeft = ear(lms.getLeftEye());
      const eRight = ear(lms.getRightEye());
      if ((eLeft + eRight) / 2 < 0.23) blinkFrames = 5;

      ctx.save();
      ctx.translate(cx, cy);
      ctx.rotate(angle);
      ctx.translate(-cx, -cy);

      const x = cx - overlayWidth / 2;

      if (blinkFrames > 0) {
        ctx.translate(cx, cy);
        ctx.scale(1.05, 1.05);
        ctx.translate(-cx, -cy);
        blinkFrames--;
      }

      ctx.drawImage(upperMaskCanvas, x, topY, overlayWidth, upperH);
      ctx.drawImage(lowerMaskCanvas, x, topY + upperH + jaw, overlayWidth, lowerH);

      ctx.restore();
    }
  </script>
</body>
</html>
