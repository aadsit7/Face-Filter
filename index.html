<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Snapchat-Style Face Filter</title>
  <!-- Tailwind for layout / styling -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- TensorFlow.js (required by face-api.js) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <!-- face-api.js for detection + landmarks -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
    }
    .tab-active {
      background-color: rgb(37 99 235); /* blue-600 */
      color: #fff;
    }
    .tab-inactive {
      background-color: transparent;
      color: rgb(55 65 81); /* gray-700 */
    }
  </style>
</head>
<body class="bg-gray-50 min-h-screen flex flex-col">
  <div class="container mx-auto px-4 sm:px-6 lg:px-8 py-6 flex-1 flex flex-col">
    <header class="mb-4">
      <h1 class="text-2xl sm:text-3xl font-semibold leading-tight">
        Snapchat-Style Face Filter
      </h1>
      <p class="text-gray-600 mt-1 text-sm sm:text-base">
        1) Upload a mask image (person, caricature, dog, cat) &nbsp; 2) Use your camera to apply it as a live face filter.
      </p>
    </header>
    <!-- Tabs -->
    <nav
      class="flex mb-4 bg-white rounded-full p-1 shadow-md text-sm sm:text-base"
      role="tablist"
      aria-label="Tabs"
    >
      <button
        id="tab-upload-btn"
        class="flex-1 py-2 px-4 rounded-full font-medium tab-active"
        data-tab="upload"
        role="tab"
        aria-selected="true"
        aria-controls="upload-tab"
      >
        Upload Image
      </button>
      <button
        id="tab-camera-btn"
        class="flex-1 py-2 px-4 rounded-full font-medium tab-inactive"
        data-tab="camera"
        role="tab"
        aria-selected="false"
        aria-controls="camera-tab"
      >
        Camera Filter
      </button>
    </nav>
    <main class="flex-1">
      <!-- Upload Tab -->
      <section
        id="upload-tab"
        class="tab-content bg-white rounded-2xl shadow-md p-4 sm:p-6"
        role="tabpanel"
        aria-labelledby="tab-upload-btn"
      >
        <h2 class="text-lg sm:text-xl font-medium mb-3">
          Upload Filter Image
        </h2>
        <p class="text-gray-700 text-sm sm:text-base mb-3">
          Choose a PNG/JPG image that will act as your face filter (for example, a dog face, cat, caricature, or person).
        </p>
        <label
          for="upload-input"
          class="inline-block bg-blue-600 hover:bg-blue-700 text-white rounded-full px-5 py-2 text-sm sm:text-base cursor-pointer shadow-sm mb-4"
        >
          Choose Image
        </label>
        <input
          type="file"
          id="upload-input"
          accept="image/png, image/jpeg"
          class="hidden"
        />
        <div id="upload-preview-wrapper" class="mt-2 hidden">
          <p class="text-gray-600 text-sm mb-2">Preview:</p>
          <img
            id="upload-preview"
            alt="Preview of uploaded image"
            class="max-w-full h-auto rounded-lg border border-gray-200"
          />
        </div>
        <p
          id="upload-message"
          class="text-sm sm:text-base text-green-700 mt-3 hidden"
        >
          Image uploaded! Switch to the <strong>Camera Filter</strong> tab to apply the filter.
        </p>
      </section>
      <!-- Camera Tab -->
      <section
        id="camera-tab"
        class="tab-content bg-white rounded-2xl shadow-md p-4 sm:p-6 mt-4 hidden"
        role="tabpanel"
        aria-labelledby="tab-camera-btn"
      >
        <h2 class="text-lg sm:text-xl font-medium mb-3">
          Camera Filter
        </h2>
        <p
          id="no-image-message"
          class="text-gray-700 text-sm sm:text-base"
        >
          Please upload an image in the <strong>Upload Image</strong> tab first.
        </p>
        <div class="mt-3 flex flex-wrap gap-2 items-center">
          <button
            id="start-camera"
            class="bg-blue-600 hover:bg-blue-700 text-white rounded-full px-5 py-2 text-sm sm:text-base shadow-sm hidden"
          >
            Start Camera
          </button>
          <button
            id="stop-camera"
            class="bg-red-600 hover:bg-red-700 text-white rounded-full px-5 py-2 text-sm sm:text-base shadow-sm hidden"
          >
            Stop Camera
          </button>
        </div>
        <div
          id="camera-container"
          class="relative w-full mt-4 hidden"
        >
          <!-- For iPhone Safari: autoplay + muted + playsinline -->
          <video
            id="video"
            class="hidden"
            autoplay
            muted
            playsinline
          ></video>
          <canvas
            id="canvas"
            class="max-w-full h-auto rounded-lg border border-gray-200"
          ></canvas>
        </div>
        <p
          id="status-message"
          class="text-xs sm:text-sm text-gray-500 mt-3"
        >
          Models loading...
        </p>
      </section>
    </main>
  </div>
  <script>
    // ======= Global state =======
    let uploadedImage = null; // original image
    let upperMaskCanvas = null; // offscreen canvas top half
    let lowerMaskCanvas = null; // offscreen canvas bottom half
    let video = null;
    let canvas = null;
    let ctx = null;
    let modelsLoaded = false;
    let isCameraRunning = false;
    let animationFrameId = null;
    // mouth baseline for closed mouth
    let baselineMouthOpen = null;
    // simple blink tracking
    let blinkFrames = 0;
    // ======= Tab logic =======
    const uploadTabBtn = document.getElementById("tab-upload-btn");
    const cameraTabBtn = document.getElementById("tab-camera-btn");
    const uploadTab = document.getElementById("upload-tab");
    const cameraTab = document.getElementById("camera-tab");
    function showTab(tab) {
      if (tab === "upload") {
        uploadTab.classList.remove("hidden");
        cameraTab.classList.add("hidden");
        uploadTabBtn.classList.add("tab-active");
        uploadTabBtn.classList.remove("tab-inactive");
        cameraTabBtn.classList.add("tab-inactive");
        cameraTabBtn.classList.remove("tab-active");
        // When leaving camera tab, stop camera
        stopCamera();
      } else {
        uploadTab.classList.add("hidden");
        cameraTab.classList.remove("hidden");
        cameraTabBtn.classList.add("tab-active");
        cameraTabBtn.classList.remove("tab-inactive");
        uploadTabBtn.classList.add("tab-inactive");
        uploadTabBtn.classList.remove("tab-active");
        updateCameraUIState();
      }
    }
    uploadTabBtn.addEventListener("click", () => showTab("upload"));
    cameraTabBtn.addEventListener("click", () => showTab("camera"));
    // ======= Model loading =======
    async function loadModels() {
      const status = document.getElementById("status-message");
      try {
        status.textContent = "Loading face detection models...";
        await tf.setBackend('webgl');
        await tf.ready();
        const MODEL_URL = "https://justadudewhohacks.github.io/face-api.js/models";
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
          faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        ]);
        modelsLoaded = true;
        status.textContent =
          "Models loaded. Upload an image, then switch to Camera Filter.";
        updateCameraUIState();
      } catch (err) {
        console.error("Error loading models:", err);
        status.textContent =
          "Error loading models. Please refresh the page or try again later.";
      }
    }
    // ======= Upload + split mask =======
    const uploadInput = document.getElementById("upload-input");
    const uploadPreview = document.getElementById("upload-preview");
    const uploadPreviewWrapper = document.getElementById("upload-preview-wrapper");
    const uploadMessage = document.getElementById("upload-message");
    uploadInput.addEventListener("change", (event) => {
      const file = event.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = (e) => {
        const img = new Image();
        img.onload = () => {
          uploadedImage = img;
          uploadPreview.src = e.target.result;
          uploadPreviewWrapper.classList.remove("hidden");
          uploadMessage.classList.remove("hidden");
          // create upper & lower mask canvases
          createMaskLayersFromImage(img);
          // reset mouth baseline
          baselineMouthOpen = null;
          updateCameraUIState();
        };
        img.src = e.target.result;
      };
      reader.readAsDataURL(file);
    });
    function createMaskLayersFromImage(img) {
      // Split roughly 55% top, 45% bottom (often more forehead/eyes)
      const splitRatio = 0.55;
      const splitY = img.height * splitRatio;
      // Upper mask
      upperMaskCanvas = document.createElement("canvas");
      upperMaskCanvas.width = img.width;
      upperMaskCanvas.height = splitY;
      const upperCtx = upperMaskCanvas.getContext("2d");
      upperCtx.drawImage(img, 0, 0, img.width, splitY, 0, 0, img.width, splitY);
      // Lower mask
      lowerMaskCanvas = document.createElement("canvas");
      lowerMaskCanvas.width = img.width;
      lowerMaskCanvas.height = img.height - splitY;
      const lowerCtx = lowerMaskCanvas.getContext("2d");
      lowerCtx.drawImage(
        img,
        0,
        splitY,
        img.width,
        img.height - splitY,
        0,
        0,
        img.width,
        img.height - splitY
      );
    }
    // ======= Camera control =======
    const noImageMessage = document.getElementById("no-image-message");
    const startCameraBtn = document.getElementById("start-camera");
    const stopCameraBtn = document.getElementById("stop-camera");
    const cameraContainer = document.getElementById("camera-container");
    const statusMessage = document.getElementById("status-message");
    function updateCameraUIState() {
      if (!cameraTab.classList.contains("hidden")) {
        if (!uploadedImage) {
          noImageMessage.textContent =
            "Please upload an image in the Upload Image tab first.";
          noImageMessage.classList.remove("hidden");
          startCameraBtn.classList.add("hidden");
          stopCameraBtn.classList.add("hidden");
          cameraContainer.classList.add("hidden");
        } else if (!modelsLoaded) {
          noImageMessage.textContent =
            "Models are still loading. Please wait a moment...";
          noImageMessage.classList.remove("hidden");
          startCameraBtn.classList.add("hidden");
          stopCameraBtn.classList.add("hidden");
          cameraContainer.classList.add("hidden");
        } else {
          noImageMessage.textContent =
            "Press 'Start Camera' to apply the filter.";
          noImageMessage.classList.remove("hidden");
          startCameraBtn.classList.remove("hidden");
          stopCameraBtn.classList.add("hidden");
          cameraContainer.classList.add("hidden");
        }
      }
    }
    startCameraBtn.addEventListener("click", startCamera);
    stopCameraBtn.addEventListener("click", stopCamera);
    async function startCamera() {
      if (!uploadedImage || !modelsLoaded) return;
      video = document.getElementById("video");
      canvas = document.getElementById("canvas");
      ctx = canvas.getContext("2d");
      const constraints = {
        video: {
          facingMode: "user",
        },
        audio: false,
      };
      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          isCameraRunning = true;
          noImageMessage.classList.add("hidden");
          startCameraBtn.classList.add("hidden");
          stopCameraBtn.classList.remove("hidden");
          cameraContainer.classList.remove("hidden");
          statusMessage.textContent =
            "Camera running. Move your head and mouth to see the filter animate.";
          renderLoop();
        };
        await video.play();
      } catch (err) {
        console.error("Error accessing camera:", err);
        alert(
          "Camera access denied or unavailable. Please check browser permissions."
        );
      }
    }
    function stopCamera() {
      if (video && video.srcObject) {
        video.srcObject.getTracks().forEach((track) => track.stop());
        video.srcObject = null;
      }
      isCameraRunning = false;
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
        animationFrameId = null;
      }
      cameraContainer.classList.add("hidden");
      stopCameraBtn.classList.add("hidden");
      startCameraBtn.classList.remove("hidden");
      if (uploadedImage && modelsLoaded) {
        noImageMessage.textContent =
          "Press 'Start Camera' to apply the filter.";
        noImageMessage.classList.remove("hidden");
      }
    }
    // ======= Helpers =======
    function distance(p1, p2) {
      const dx = p1.x - p2.x;
      const dy = p1.y - p2.y;
      return Math.sqrt(dx * dx + dy * dy);
    }
    function averagePointArray(points) {
      const sum = points.reduce(
        (acc, p) => {
          acc.x += p.x;
          acc.y += p.y;
          return acc;
        },
        { x: 0, y: 0 }
      );
      return {
        x: sum.x / points.length,
        y: sum.y / points.length,
      };
    }
    // Eye aspect ratio approximation
    function eyeAspectRatio(eyePoints) {
      if (!eyePoints || eyePoints.length < 6) return 0.3;
      const p1 = eyePoints[0];
      const p2 = eyePoints[1];
      const p3 = eyePoints[2];
      const p4 = eyePoints[3];
      const p5 = eyePoints[4];
      const p6 = eyePoints[5];
      const vertical1 = distance(p2, p6);
      const vertical2 = distance(p3, p5);
      const horizontal = distance(p1, p4);
      const ear = (vertical1 + vertical2) / (2.0 * horizontal);
      return ear;
    }
    // ======= Render loop =======
    async function renderLoop() {
      if (!isCameraRunning || !video || video.readyState < 2) {
        return;
      }
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const options = new faceapi.TinyFaceDetectorOptions({
        inputSize: 320,
        scoreThreshold: 0.5,
      });
      const detection = await faceapi
        .detectSingleFace(canvas, options)
        .withFaceLandmarks();
      if (detection && upperMaskCanvas && lowerMaskCanvas) {
        drawFilter(detection);
      }
      animationFrameId = requestAnimationFrame(renderLoop);
    }
    function drawFilter(detection) {
      const landmarks = detection.landmarks;
      const box = detection.detection.box;
      const mouth = landmarks.getMouth();
      const leftEye = landmarks.getLeftEye();
      const rightEye = landmarks.getRightEye();
      const leftEyeCenter = averagePointArray(leftEye);
      const rightEyeCenter = averagePointArray(rightEye);
      // Face center around midpoint of eyes & a bit down toward nose
      const eyeMidX = (leftEyeCenter.x + rightEyeCenter.x) / 2;
      const eyeMidY = (leftEyeCenter.y + rightEyeCenter.y) / 2;
      const nose = landmarks.getNose();
      const noseCenter = averagePointArray(nose);
      const faceCenterX = eyeMidX;
      const faceCenterY = (eyeMidY * 2 + noseCenter.y) / 3;
      // Head rotation (angle) from eye line
      const dx = rightEyeCenter.x - leftEyeCenter.x;
      const dy = rightEyeCenter.y - leftEyeCenter.y;
      const angle = Math.atan2(dy, dx);
      const faceWidth = box.width;
      const overlayWidth = faceWidth * 2.2; // tune as needed
      const maskAspect = uploadedImage.height / uploadedImage.width;
      const overlayTotalHeight = overlayWidth * maskAspect;
      // We'll split this into upper + lower scaled heights
      const upperRatio = upperMaskCanvas.height / uploadedImage.height;
      const lowerRatio = lowerMaskCanvas.height / uploadedImage.height;
      const upperHeightScaled = overlayTotalHeight * upperRatio;
      const lowerHeightScaled = overlayTotalHeight * lowerRatio;
      // Compute base top Y so that the mask roughly covers from forehead down
      const overlayTopY = faceCenterY - overlayTotalHeight * 0.5 - (faceWidth * 0.1); // slight upward adjustment for better alignment
      // Mouth openness (inner lip points)
      const m = mouth;
      // approximate top inner lip: indices 13,14,15; bottom inner lip: 19,18,17
      const openness1 = Math.abs(m[13].y - m[19].y);
      const openness2 = Math.abs(m[14].y - m[18].y);
      const openness3 = Math.abs(m[15].y - m[17].y);
      const mouthOpen = (openness1 + openness2 + openness3) / 3;
      if (baselineMouthOpen === null) {
        baselineMouthOpen = mouthOpen;
      } else {
        // smooth baseline a bit
        baselineMouthOpen = baselineMouthOpen * 0.9 + mouthOpen * 0.1;
      }
      const openDelta = Math.max(0, mouthOpen - baselineMouthOpen * 1.1);
      const jawOffset = openDelta * 1.5; // jaw movement factor
      // Blink detection
      const earLeft = eyeAspectRatio(leftEye);
      const earRight = eyeAspectRatio(rightEye);
      const earAvg = (earLeft + earRight) / 2;
      const blinkThreshold = 0.23;
      if (earAvg < blinkThreshold && blinkFrames === 0) {
        blinkFrames = 5; // frames of blink effect
      }
      // Save context and apply rotation around face center
      ctx.save();
      ctx.translate(faceCenterX, faceCenterY);
      ctx.rotate(angle);
      ctx.translate(-faceCenterX, -faceCenterY);
      const overlayX = faceCenterX - overlayWidth / 2;
      const upperY = overlayTopY;
      const lowerY = overlayTopY + upperHeightScaled + jawOffset;
      // Blink effect: slight scale if blinkFrames > 0
      if (blinkFrames > 0) {
        const scale = 1.05;
        ctx.translate(faceCenterX, faceCenterY);
        ctx.scale(scale, scale);
        ctx.translate(-faceCenterX, -faceCenterY);
        blinkFrames--;
      }
      // Draw upper mask
      ctx.drawImage(
        upperMaskCanvas,
        0,
        0,
        upperMaskCanvas.width,
        upperMaskCanvas.height,
        overlayX,
        upperY,
        overlayWidth,
        upperHeightScaled
      );
      // Draw lower mask with jaw offset
      ctx.drawImage(
        lowerMaskCanvas,
        0,
        0,
        lowerMaskCanvas.width,
        lowerMaskCanvas.height,
        overlayX,
        lowerY,
        overlayWidth,
        lowerHeightScaled
      );
      ctx.restore();
    }
    // ======= Init =======
    loadModels();
  </script>
</body>
</html>
