<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Snapchat-Style Face Filter Web App</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  </head>
  <body class="bg-gray-50 font-[Inter] text-gray-900 min-h-screen flex flex-col">
    <div class="container mx-auto px-6 lg:px-12 py-6 flex-grow">
      <header class="mb-6">
        <h1 class="text-3xl font-semibold leading-tight">Snapchat-Style Face Filter</h1>
      </header>
      <nav class="flex mb-6 bg-white rounded-full p-1 shadow-md" role="tablist" aria-label="Tabs">
        <button class="tab-button flex-1 py-2 px-4 rounded-full text-center font-medium bg-blue-600 text-white transition-all duration-300" data-tab="upload" role="tab" aria-selected="true" aria-controls="upload-tab">Upload Image</button>
        <button class="tab-button flex-1 py-2 px-4 rounded-full text-center font-medium bg-transparent text-gray-700 hover:bg-gray-100 transition-all duration-300" data-tab="camera" role="tab" aria-selected="false" aria-controls="camera-tab">Camera Filter</button>
      </nav>
      <main>
        <section id="upload-tab" class="tab-content bg-white rounded-2xl shadow-md p-6 hover:shadow-lg transition-shadow duration-300" role="tabpanel" aria-labelledby="upload-tab-button">
          <h2 class="text-xl font-medium mb-4">Upload Filter Image</h2>
          <label for="upload-input" class="inline-block bg-blue-600 hover:bg-blue-700 text-white rounded-full px-6 py-2 shadow-sm cursor-pointer mb-4">Choose Image</label>
          <input type="file" id="upload-input" accept="image/png, image/jpeg" class="hidden">
          <img id="upload-preview" alt="Preview of uploaded image" class="max-w-full h-auto rounded-lg mb-4 hidden">
          <p id="upload-message" class="text-base text-gray-700 leading-relaxed hidden">Image uploaded! Switch to the Camera tab to apply the filter.</p>
        </section>
        <section id="camera-tab" class="tab-content hidden bg-white rounded-2xl shadow-md p-6 hover:shadow-lg transition-shadow duration-300" role="tabpanel" aria-labelledby="camera-tab-button">
          <h2 class="text-xl font-medium mb-4">Camera Filter</h2>
          <p id="no-image-message" class="text-base text-gray-700 leading-relaxed">Please upload an image in the Upload tab first.</p>
          <div id="camera-container" class="relative w-full hidden">
            <video id="video" playsinline autoplay muted class="hidden"></video>
            <canvas id="canvas" class="max-w-full h-auto rounded-lg"></canvas>
          </div>
          <button id="start-camera" class="bg-blue-600 hover:bg-blue-700 text-white rounded-full px-6 py-2 shadow-sm hidden">Start Camera</button>
          <button id="fullscreen-btn" class="bg-green-600 hover:bg-green-700 text-white rounded-full px-6 py-2 shadow-sm ml-4 hidden">Enter Full Screen</button>
        </section>
      </main>
    </div>
    <script>
      lucide.createIcons();
      let uploadedImage = null;
      let upperMask = null;
      let lowerMask = null;
      let video = null;
      let canvas = null;
      let isCameraRunning = false;
      let modelsLoaded = false;
      let blinkFrames = 0;
      const tabButtons = document.querySelectorAll('.tab-button');
      const tabContents = document.querySelectorAll('.tab-content');
      tabButtons.forEach(button => {
        button.addEventListener('click', () => {
          const tab = button.dataset.tab;
          tabButtons.forEach(btn => {
            btn.classList.remove('bg-blue-600', 'text-white');
            btn.classList.add('bg-transparent', 'text-gray-700', 'hover:bg-gray-100');
            btn.setAttribute('aria-selected', 'false');
          });
          button.classList.add('bg-blue-600', 'text-white');
          button.classList.remove('bg-transparent', 'text-gray-700', 'hover:bg-gray-100');
          button.setAttribute('aria-selected', 'true');
          tabContents.forEach(content => content.classList.add('hidden'));
          document.getElementById(`${tab}-tab`).classList.remove('hidden');
          if (tab === 'camera') {
            if (uploadedImage) {
              document.getElementById('no-image-message').classList.add('hidden');
              document.getElementById('start-camera').classList.remove('hidden');
              if (isCameraRunning) {
                document.getElementById('camera-container').classList.remove('hidden');
                document.getElementById('fullscreen-btn').classList.remove('hidden');
              }
            } else {
              document.getElementById('no-image-message').classList.remove('hidden');
              document.getElementById('start-camera').classList.add('hidden');
              document.getElementById('camera-container').classList.add('hidden');
              document.getElementById('fullscreen-btn').classList.add('hidden');
            }
          } else {
            stopCamera();
            document.getElementById('camera-container').classList.add('hidden');
            document.getElementById('fullscreen-btn').classList.add('hidden');
          }
        });
      });
      async function loadModels() {
        try {
          await tf.setBackend('wasm');
          await tf.ready();
          await faceapi.nets.tinyFaceDetector.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
          await faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
          modelsLoaded = true;
        } catch (error) {
          console.error('Error loading models:', error);
          alert('Failed to load face detection models. Please try again later.');
        }
      }
      async function startCamera() {
        if (!modelsLoaded || !uploadedImage) return;
        video = document.getElementById('video');
        canvas = document.getElementById('canvas');
        const noImageMsg = document.getElementById('no-image-message');
        const cameraContainer = document.getElementById('camera-container');
        const startButton = document.getElementById('start-camera');
        const fullscreenBtn = document.getElementById('fullscreen-btn');
        noImageMsg.classList.add('hidden');
        startButton.classList.add('hidden');
        cameraContainer.classList.remove('hidden');
        fullscreenBtn.classList.remove('hidden');
        const constraints = { video: { facingMode: 'user' } };
        try {
          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;
          video.setAttribute('playsinline', true);
          video.addEventListener('loadedmetadata', () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            isCameraRunning = true;
            detectAndDraw();
          }, { once: true });
          video.play();
        } catch (error) {
          console.error('Error accessing camera:', error);
          alert('Camera access denied or unavailable. Please grant permission in your browser settings.');
        }
      }
      function stopCamera() {
        if (video && video.srcObject) {
          video.srcObject.getTracks().forEach(track => track.stop());
          video.srcObject = null;
        }
        isCameraRunning = false;
      }
      // Helper function to compute Euclidean distance between two points
      function dist(p1, p2) {
        return Math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2);
      }
      async function detectAndDraw() {
        if (!isCameraRunning) return;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 320, scoreThreshold: 0.5 });
        const detections = await faceapi.detectAllFaces(canvas, options).withFaceLandmarks();
        if (detections.length > 0) {
          const detection = detections[0];
          const landmarks = detection.landmarks;
          const box = detection.detection.box;
          const leftEye = landmarks.getLeftEye();
          const rightEye = landmarks.getRightEye();
          const mouth = landmarks.getMouth();
          const eyeCenterX = (leftEye.reduce((sum, p) => sum + p.x, 0) / leftEye.length + rightEye.reduce((sum, p) => sum + p.x, 0) / rightEye.length) / 2;
          const eyeCenterY = (leftEye.reduce((sum, p) => sum + p.y, 0) / leftEye.length + rightEye.reduce((sum, p) => sum + p.y, 0) / rightEye.length) / 2;
          // Compute mouth openness: average vertical distance between inner upper and lower lip points
          // mouth[13] = point 61, mouth[19] = 67; mouth[14]=62, mouth[18]=66; mouth[15]=63, mouth[17]=65
          const openness1 = mouth[13].y - mouth[19].y;
          const openness2 = mouth[14].y - mouth[18].y;
          const openness3 = mouth[15].y - mouth[17].y;
          const mouthOpenness = (Math.abs(openness1) + Math.abs(openness2) + Math.abs(openness3)) / 3;
          // Compute Eye Aspect Ratio (EAR) for blink detection
          // Left eye EAR: (dist(43,47) + dist(44,46)) / (2 * dist(42,45))
          const leftEAR = (dist(leftEye[1], leftEye[5]) + dist(leftEye[2], leftEye[4])) / (2 * dist(leftEye[0], leftEye[3]));
          // Right eye EAR: (dist(37,41) + dist(38,40)) / (2 * dist(36,39))
          const rightEAR = (dist(rightEye[1], rightEye[5]) + dist(rightEye[2], rightEye[4])) / (2 * dist(rightEye[0], rightEye[3]));
          const avgEAR = (leftEAR + rightEAR) / 2;
          // Blink detection: if avgEAR < 0.25 and no ongoing blink effect, trigger for 5 frames
          if (avgEAR < 0.25 && blinkFrames === 0) {
            blinkFrames = 5;
          }
          const overlayWidth = box.width * 2.2;
          const fullOverlayHeight = (uploadedImage.height / uploadedImage.width) * overlayWidth;
          const halfOverlayHeight = fullOverlayHeight / 2;
          const overlayX = eyeCenterX - overlayWidth / 2;
          const upperOverlayY = eyeCenterY - fullOverlayHeight / 2 - box.height * 0.2;
          const lowerOverlayY = upperOverlayY + halfOverlayHeight + mouthOpenness * 0.5; // Offset lower mask based on mouth openness (scaled by 0.5 for subtlety)
          // Apply blink effect: scale mask slightly if blinkFrames > 0
          if (blinkFrames > 0) {
            ctx.save();
            ctx.translate(eyeCenterX, eyeCenterY);
            ctx.scale(1.05, 1.05);
            ctx.translate(-eyeCenterX, -eyeCenterY);
            blinkFrames--;
          }
          // Draw upper mask
          ctx.drawImage(upperMask, overlayX, upperOverlayY, overlayWidth, halfOverlayHeight);
          // Draw lower mask with offset
          ctx.drawImage(lowerMask, overlayX, lowerOverlayY, overlayWidth, halfOverlayHeight);
          if (blinkFrames > 0) {
            ctx.restore();
          }
        }
        requestAnimationFrame(detectAndDraw);
      }
      document.getElementById('upload-input').addEventListener('change', (event) => {
        const file = event.target.files[0];
        if (file) {
          const reader = new FileReader();
          reader.onload = (e) => {
            const preview = document.getElementById('upload-preview');
            preview.src = e.target.result;
            preview.classList.remove('hidden');
            uploadedImage = new Image();
            uploadedImage.src = e.target.result;
            uploadedImage.onload = () => {
              // Split uploadedImage into upper and lower masks using offscreen canvases
              const width = uploadedImage.width;
              const height = uploadedImage.height;
              // Upper mask: top half
              const upperCanvas = document.createElement('canvas');
              upperCanvas.width = width;
              upperCanvas.height = height / 2;
              const upperCtx = upperCanvas.getContext('2d');
              upperCtx.drawImage(uploadedImage, 0, 0, width, height / 2, 0, 0, width, height / 2);
              upperMask = new Image();
              upperMask.src = upperCanvas.toDataURL();
              // Lower mask: bottom half
              const lowerCanvas = document.createElement('canvas');
              lowerCanvas.width = width;
              lowerCanvas.height = height / 2;
              const lowerCtx = lowerCanvas.getContext('2d');
              lowerCtx.drawImage(uploadedImage, 0, height / 2, width, height / 2, 0, 0, width, height / 2);
              lowerMask = new Image();
              lowerMask.src = lowerCanvas.toDataURL();
              document.getElementById('upload-message').classList.remove('hidden');
            };
          };
          reader.readAsDataURL(file);
        }
      });
      document.getElementById('start-camera').addEventListener('click', startCamera);
      document.getElementById('fullscreen-btn').addEventListener('click', () => {
        if (!document.fullscreenElement) {
          canvas.requestFullscreen().catch(err => console.error('Fullscreen error:', err));
        } else {
          document.exitFullscreen();
        }
      });
      document.addEventListener('fullscreenchange', () => {
        const btn = document.getElementById('fullscreen-btn');
        btn.textContent = document.fullscreenElement ? 'Exit Full Screen' : 'Enter Full Screen';
      });
      loadModels();
    </script>
  </body>
</html>
